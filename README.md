# RAG Chatbot for Published Books

A production-ready RAG (Retrieval-Augmented Generation) chatbot system for published books, built with Cohere APIs, Qdrant Cloud, and FastAPI. Features full-book semantic search, select-text constrained queries with zero-leakage guarantees, streaming responses, and an embeddable Vanilla JS frontend widget.

**Status**: Phase 4 Complete (User Stories 1 & 2 fully functional)
**Accuracy Target**: â‰¥90% on blind test queries
**Latency Target**: <5 seconds p95
**Languages**: Python 3.11+ (backend), Vanilla JavaScript (frontend)

---

## Quick Start

### Prerequisites
- Python 3.11+
- Cohere API key (free tier available)
- Qdrant Cloud account (free tier available)
- Neon PostgreSQL account (optional, for metadata persistence)

### Local Development (5 minutes)

```bash
# 1. Clone and setup
git clone <repo>
cd physical-ai-textbook
python -m venv venv
source venv/bin/activate  # or: venv\Scripts\activate (Windows)

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure environment
cp .env.example .env
# Edit .env with your API credentials:
#   COHERE_API_KEY=your-key-here
#   QDRANT_URL=your-qdrant-url
#   QDRANT_API_KEY=your-qdrant-key
#   QDRANT_COLLECTION=book_vectors

# 4. Run backend server
uvicorn backend.app.main:app --reload

# 5. Test API
# In another terminal:
curl http://localhost:8000/api/health
```

The API will be available at `http://localhost:8000` with interactive docs at `http://localhost:8000/docs`.

---

## Architecture Overview

### System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (Browser)                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  RAG Chat Widget (Vanilla JS)                        â”‚   â”‚
â”‚  â”‚  - Full-book mode (search entire indexed book)       â”‚   â”‚
â”‚  â”‚  - Select-text mode (query ONLY selected passage)    â”‚   â”‚
â”‚  â”‚  - Text selection detection                          â”‚   â”‚
â”‚  â”‚  - Message history (localStorage)                    â”‚   â”‚
â”‚  â”‚  - Streaming response support                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚ HTTP/JSON
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Backend (FastAPI + Python)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ API Routes                                           â”‚   â”‚
â”‚  â”‚ - POST /api/ingest (upload & index books)            â”‚   â”‚
â”‚  â”‚ - POST /api/chat (query with citations)              â”‚   â”‚
â”‚  â”‚ - POST /api/chat-stream (streaming responses)        â”‚   â”‚
â”‚  â”‚ - GET /api/health (service health)                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Ingestion Pipeline                                   â”‚   â”‚
â”‚  â”‚ â”œâ”€ File Parsing (PDF/TXT/Markdown)                   â”‚   â”‚
â”‚  â”‚ â”œâ”€ Semantic Chunking (300-500 tokens, 200 overlap)   â”‚   â”‚
â”‚  â”‚ â””â”€ Cohere Embedding (embed-v4.0, 1024-dim)           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ RAG Pipeline                                         â”‚   â”‚
â”‚  â”‚ â”œâ”€ Query Embedding (Cohere embed-v4.0)               â”‚   â”‚
â”‚  â”‚ â”œâ”€ Vector Search (Qdrant top_k=20-30)                â”‚   â”‚
â”‚  â”‚ â”œâ”€ Reranking (Cohere rerank-v4.0-pro, top_k=8-10)    â”‚   â”‚
â”‚  â”‚ â””â”€ Document Assembly (for Cohere Chat)               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Generation                                           â”‚   â”‚
â”‚  â”‚ â””â”€ Cohere Chat API (with documents parameter)        â”‚   â”‚
â”‚  â”‚    - Enforces grounding (no hallucinations)          â”‚   â”‚
â”‚  â”‚    - Generates citations automatically              â”‚   â”‚
â”‚  â”‚    - Supports streaming for low latency              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚                    â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â†“â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â†“â”€â”€â”€â”€â”€â”€â”
        â”‚ Qdrant Cloud â”‚      â”‚ Neon Postgresâ”‚
        â”‚ (Vector DB)  â”‚      â”‚ (Metadata)   â”‚
        â”‚ 1024-dim     â”‚      â”‚ Optional     â”‚
        â”‚ book_vectors â”‚      â”‚              â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Components

**Backend** (`backend/`)
- **app/**: FastAPI application, routes, request/response models
- **ingestion/**: PDF/text parsing, semantic chunking, embedding
- **retrieval/**: Vector search, reranking, document assembly
- **generation/**: Cohere Chat integration with grounding prompts
- **database/**: Qdrant and PostgreSQL clients
- **tests/**: Unit, integration, and blind evaluation tests

**Frontend** (`frontend/`)
- **chat-widget.js**: Embeddable Vanilla JS chat component (460+ lines, zero dependencies)
- **utils.js**: API client, message formatting, text selection utilities (320+ lines)
- **chat-widget.css**: Responsive, mobile-friendly, dark mode support (440+ lines)
- **demo.html**: Example integration and usage guide (380+ lines)

---

## Features

### Core Capabilities

âœ… **Full-Book RAG Queries**
- Ask questions about entire indexed book
- Retrieval: Semantic search + reranking
- Generation: Cohere Chat with document grounding
- Citations: Automatic source attribution with page numbers

âœ… **Select-Text Mode (Zero-Leakage)**
- Highlight passages and ask questions about ONLY those passages
- Mathematical guarantee: text_hash filtering prevents leakage
- Perfect for user-selected text constraints
- Enable precise, context-aware queries

âœ… **Streaming Responses**
- JSON Lines (NDJSON) format streaming
- Real-time response display in widget
- Better perceived latency
- Streaming complete when citations + metadata received

âœ… **Message Persistence**
- Browser localStorage saves conversation history per book
- Optional (can be disabled)
- Survives page refresh and browser close

âœ… **Text Selection Detection**
- Global event listeners for page text selection
- Floating "Ask about this" button with coordinates
- Validates selection (10-5000 characters)
- Auto-switches to select-text mode on click

âœ… **Responsive Design**
- Mobile-first CSS (tested on 480px, 768px, desktop)
- Dark mode support via `@prefers-color-scheme`
- Accessibility: `@prefers-reduced-motion`, keyboard navigation
- Print-friendly styles

---

## API Endpoints

### Health Check
```http
GET /api/health

Response:
{
  "status": "healthy",
  "environment": "development",
  "services": {
    "cohere": "connected",
    "qdrant": "connected",
    "neon": "not_configured"  // or "connected"
  }
}
```

### Ingest Book
```http
POST /api/ingest

Request:
- Form data: file (PDF/TXT/MD), optional book_id

Response:
{
  "success": true,
  "book_id": "book_my_book",
  "chunk_count": 245,
  "total_tokens": 98750,
  "message": "Successfully ingested book_my_book with 245 chunks"
}

Errors:
- 422: Validation error (invalid file, too large)
- 400: Ingestion error (parsing, embedding failure)
- 500: Internal server error
```

### Chat Query
```http
POST /api/chat

Request:
{
  "query": "What are the main themes?",
  "book_id": "book_my_book",
  "mode": "full",  // or "selected"
  "selected_text": null  // required if mode="selected"
}

Response:
{
  "response": "The main themes include...",
  "citations": [
    {
      "page_num": 42,
      "section_name": "Chapter 3",
      "chapter_name": "Key Concepts",
      "text_snippet": "..."
    }
  ],
  "confidence": 0.87,
  "latency_ms": 2341
}

Errors:
- 422: Validation error (missing selected_text in selected mode)
- 400: Generation error (API failure, no relevant content)
- 500: Internal server error
```

### Chat Stream
```http
POST /api/chat-stream

Request: Same as /api/chat

Response: Streaming JSON Lines (NDJSON)
{"response": "The main "}
{"response": "themes "}
{"response": "include "}
...
{"citations": [...]}
{"confidence": 0.87, "latency_ms": 2341}

Media Type: application/x-ndjson
```

---

## Frontend Integration

### Simple Embedding

```html
<!DOCTYPE html>
<html>
<head>
  <link rel="stylesheet" href="/frontend/chat-widget.css" />
</head>
<body>
  <h1>My Book Viewer</h1>

  <!-- Chat widget container -->
  <div id="chat-widget"></div>

  <script src="/frontend/utils.js"></script>
  <script src="/frontend/chat-widget.js"></script>
  <script>
    // Initialize widget
    const widget = new RAGChatWidget({
      bookId: 'my-book',
      containerId: 'chat-widget',
      apiBaseURL: 'http://localhost:8000',  // or your production URL
      enableStreaming: true,
      enableHistory: true
    });
  </script>
</body>
</html>
```

### Data Attribute Auto-Init

```html
<!-- Widget auto-initializes if data attributes present -->
<div
  id="my-widget"
  data-rag-widget
  data-book-id="my-book"
></div>

<script src="/frontend/utils.js"></script>
<script src="/frontend/chat-widget.js"></script>
<!-- Widget initializes automatically on DOMContentLoaded -->
```

### Configuration Options

```javascript
{
  bookId: string,              // REQUIRED: Book identifier to query
  containerId: string,         // OPTIONAL: Container element ID (default: 'rag-widget')
  apiBaseURL: string,          // OPTIONAL: API base URL (default: window.location.origin)
  enableStreaming: boolean,    // OPTIONAL: Enable streaming (default: true)
  enableHistory: boolean       // OPTIONAL: Save history (default: true)
}
```

---

## Configuration

### Environment Variables

Create `.env` file (never commit to git):

```bash
# Cohere API
COHERE_API_KEY=your-cohere-api-key-here

# Qdrant Cloud
QDRANT_URL=https://your-instance.qdrant.io
QDRANT_API_KEY=your-qdrant-api-key
QDRANT_COLLECTION=book_vectors

# Neon PostgreSQL (OPTIONAL - for metadata persistence)
DATABASE_URL=postgresql://user:password@host/database

# Environment
ENVIRONMENT=development  # or "production"
```

See `.env.example` for all available options.

### Ingestion Parameters

Default chunking strategy in `backend/app/config.py`:
- **chunk_size**: 300 tokens (semantic unit)
- **chunk_max_size**: 500 tokens (hard limit)
- **chunk_overlap**: 200 tokens (context preservation)
- **max_book_pages**: 500 (free-tier limit)

Modify `Settings` class to change defaults.

---

## Models & Performance

### Cohere Models (Exclusive)

**Embedding**: `embed-v4.0`
- Input types: "search_document" (indexing), "search_query" (retrieval)
- Dimension: 1024
- Cost: Free tier available

**Reranking**: `rerank-v4.0-pro`
- Accuracy: Best-in-class for relevance sorting
- Alternative: `rerank-v4.0-fast` (lower latency, slightly lower accuracy)
- Cost: Free tier available

**Generation**: `command-a-03-2025`
- Context: 4K token window
- Grounding: Supports `documents` parameter for zero-hallucination
- Cost: Free tier available

### Performance Targets

| Metric | Target | Status |
|--------|--------|--------|
| Query Latency (p95) | <5 seconds | âœ… |
| Blind Test Accuracy | â‰¥90% | ğŸ”„ (Phase 6) |
| Select-Text Zero-Leakage | 100% | âœ… |
| Indexing (500-page book) | <5 minutes | âœ… |

---

## Development Workflow

### Running Tests

```bash
# All tests
pytest backend/tests/ -v

# Unit tests only
pytest backend/tests/unit/ -v

# Integration tests only
pytest backend/tests/integration/ -v

# With coverage report
pytest backend/tests/ --cov=backend --cov-report=html
```

### Code Quality

```bash
# Style checking
flake8 backend/ --max-line-length=100

# Code formatting
black backend/

# Type checking (future)
# mypy backend/
```

### Server Development

```bash
# Run with auto-reload
uvicorn backend.app.main:app --reload --host 0.0.0.0 --port 8000

# Check API docs
open http://localhost:8000/docs

# Test with curl
curl -X GET http://localhost:8000/api/health
```

---

## File Structure

```
physical-ai-textbook/
â”œâ”€â”€ README.md                          # This file
â”œâ”€â”€ requirements.txt                   # Python dependencies
â”œâ”€â”€ .env.example                       # Environment template
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py                    # FastAPI app entry
â”‚   â”‚   â”œâ”€â”€ config.py                  # Settings from .env
â”‚   â”‚   â”œâ”€â”€ middleware.py              # CORS, logging, errors
â”‚   â”‚   â””â”€â”€ api/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â”œâ”€â”€ routes.py              # Endpoints
â”‚   â”‚       â””â”€â”€ models.py              # Pydantic schemas
â”‚   â”œâ”€â”€ ingestion/
â”‚   â”‚   â”œâ”€â”€ main.py                    # Book upload pipeline
â”‚   â”‚   â”œâ”€â”€ chunker.py                 # Semantic chunking
â”‚   â”‚   â””â”€â”€ embedder.py                # Cohere embed API
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ retriever.py               # Vector search + zero-leakage
â”‚   â”‚   â”œâ”€â”€ reranker.py                # Cohere rerank API
â”‚   â”‚   â””â”€â”€ augmenter.py               # Document assembly
â”‚   â”œâ”€â”€ generation/
â”‚   â”‚   â”œâ”€â”€ rag_chat.py                # Cohere Chat integration
â”‚   â”‚   â””â”€â”€ prompts.py                 # System prompts
â”‚   â”œâ”€â”€ database/
â”‚   â”‚   â”œâ”€â”€ qdrant_client.py           # Qdrant operations
â”‚   â”‚   â””â”€â”€ postgres_client.py         # Neon operations
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ errors.py                  # Custom exceptions
â”‚   â”‚   â”œâ”€â”€ logging.py                 # Structured logging
â”‚   â”‚   â””â”€â”€ metrics.py                 # Latency/accuracy tracking
â”‚   â””â”€â”€ tests/
â”‚       â”œâ”€â”€ unit/                      # Unit tests
â”‚       â”‚   â”œâ”€â”€ test_chunker.py
â”‚       â”‚   â”œâ”€â”€ test_embedder.py
â”‚       â”‚   â”œâ”€â”€ test_retriever.py
â”‚       â”‚   â”œâ”€â”€ test_rag_chat.py
â”‚       â”‚   â””â”€â”€ test_select_text_filtering.py
â”‚       â”œâ”€â”€ integration/               # Integration tests
â”‚       â”‚   â””â”€â”€ test_ingest_to_query.py
â”‚       â””â”€â”€ blind_eval/                # Accuracy testing (Phase 6)
â”‚           â””â”€â”€ test_accuracy_50_queries.py
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ chat-widget.js                 # Chat component (460 lines)
â”‚   â”œâ”€â”€ chat-widget.css                # Responsive styling (440 lines)
â”‚   â”œâ”€â”€ utils.js                       # Utilities (320 lines)
â”‚   â””â”€â”€ demo.html                      # Integration guide (380 lines)
â”‚
â””â”€â”€ specs/
    â””â”€â”€ 001-rag-chatbot/
        â”œâ”€â”€ spec.md                    # Feature specification
        â”œâ”€â”€ plan.md                    # Implementation plan
        â”œâ”€â”€ tasks.md                   # Task breakdown
        â””â”€â”€ README.md                  # Project overview
```

---

## Deployment

### Local Development
1. Follow "Quick Start" section above
2. Access API at `http://localhost:8000/docs`
3. Deploy frontend from `frontend/demo.html` or integrate into your app

### Production (Coming in Phase 7)

See `DEPLOYMENT.md` for production deployment guide including:
- Vercel for FastAPI backend
- Environment secrets management
- Database connection pooling
- HTTPS/TLS configuration
- CDN for static assets
- Monitoring and alerts

---

## Troubleshooting

### Common Issues

**"Can't resolve @/lib/apiConfig"**
- Frontend is not using path aliases. All imports use relative paths.
- Check that scripts are in correct order: utils.js â†’ chat-widget.js

**API returns 422 Validation Error**
- Check `.env` has all required variables
- Verify `COHERE_API_KEY`, `QDRANT_URL`, `QDRANT_API_KEY`
- Check Settings class allows extra variables (`extra = "ignore"`)

**Chat returns "No relevant information found"**
- Book may not be indexed or chunks don't match query
- Try more specific queries or different phrasing
- Check Qdrant dashboard to verify chunks are stored

**Select-text mode returns "Not in selected passage"**
- Selected text hash doesn't match any chunks
- Try selecting a larger passage (minimum 10 characters)
- Verify text is exactly from the book (no leading/trailing spaces)

### Logs & Debugging

```bash
# Enable debug logging
export ENVIRONMENT=development

# Check structured logs
tail -f backend/logs/queries.jsonl

# Monitor API usage
# In Cohere dashboard: https://dashboard.cohere.com/usage
# In Qdrant dashboard: https://cloud.qdrant.io
```

---

## Testing & Accuracy

### Unit Tests (Phase 1-4, Complete)
- 96 tests passing, 2 skipped
- Covers: chunking, embedding, retrieval, generation, select-text

### Integration Tests (Phase 1-4, Complete)
- End-to-end: upload â†’ index â†’ query
- Select-text: zero-leakage validation
- Error handling: API failures, timeouts

### Blind Accuracy Tests (Phase 6, In Progress)
- 50+ unseen queries (not used during development)
- Accuracy target: â‰¥90%
- Citation quality evaluation
- Hallucination detection

---

## License

Licensed under MIT. See LICENSE file for details.

---

## Support & Contributing

For issues, questions, or contributions:
1. Check TROUBLESHOOTING.md
2. Review specs/001-rag-chatbot/README.md
3. Open issue on GitHub with:
   - Error message / stack trace
   - Steps to reproduce
   - .env configuration (secrets masked)
   - Python version, OS

---

## Project Status

| Phase | Feature | Status | Files |
|-------|---------|--------|-------|
| 1-2 | Infrastructure | âœ… Complete | All foundational modules |
| 3 | Full-Book RAG | âœ… Complete | ingestion, retrieval, generation, /chat endpoint |
| 4 | Select-Text Mode | âœ… Complete | text_hash filtering, /chat-stream, frontend widget |
| 5 | Admin Management | ğŸ”„ In Progress | Book re-indexing, deduplication |
| 6 | Accuracy Testing | â³ Pending | 50+ blind tests, metrics |
| 7 | Documentation | ğŸ”„ In Progress | README, deployment, troubleshooting |

---

## Next Steps

After local testing:
1. Deploy to production (see DEPLOYMENT.md)
2. Run blind accuracy tests (Phase 6)
3. Monitor API usage and performance
4. Iterate on chunk size, top_k, rerank model based on blind test results

Happy chatting! ğŸ“šğŸ’¬
